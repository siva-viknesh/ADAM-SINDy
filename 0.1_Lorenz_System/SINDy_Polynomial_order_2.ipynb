{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "##### Author  : SIVA VIKNESH \n",
    "##### Email   : siva.viknesh@sci.utah.edu / sivaviknesh14@gmail.com \n",
    "##### Address : SCI INSTITUTE, UNIVERSITY OF UTAH, SALT LAKE CITY, UTAH, USA \n",
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.ticker as plticker\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import integrate\n",
    "\n",
    "rcParams.update({'font.size': 18})\n",
    "plt.rcParams['figure.figsize'] = [12, 12]\n",
    "import vtk\n",
    "from vtk.util import numpy_support as VN\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Lorenz system of differential equations:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dot{x} & = \\sigma(y-x) \\\\\n",
    "\\dot{y} & = \\rho x - y - xz \\\\\n",
    "\\dot{z} & = -\\beta z + xy\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Parameters: \\\\(\\sigma\\\\), \\\\(\\beta\\\\), and \\\\(\\rho\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simulate the Lorenz System\n",
    "\n",
    "dt = 0.01\n",
    "T = 50\n",
    "t = np.arange(0,T+dt,dt)\n",
    "beta = 8/3\n",
    "sigma = 10\n",
    "rho = 28\n",
    "\n",
    "# CASE I\n",
    "def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "    x, y, z = x_y_z\n",
    "    return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "np.random.seed(123)\n",
    "x0 = (-8, 7, 27)\n",
    "x_t = integrate.odeint(lorenz_deriv, x0, t,rtol=10**(-12),atol=10**(-12)*np.ones_like(x0))\n",
    "x, y, z = x_t.T\n",
    "\n",
    "fig,ax = plt.subplots(1,1,subplot_kw={'projection': '3d'})\n",
    "plt.plot(x, y, z, linewidth=1)\n",
    "ax.view_init(30, 140)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTING THE COMBINATIONS AMONG THE THREE CHOSEN TEMPORAL MODES\n",
    "def poolData(yin,nVars,polyorder):\n",
    "    n = yin.shape[0]\n",
    "    yout = np.zeros((n,1))\n",
    "\n",
    "    # poly order 0\n",
    "    yout[:,0] = np.ones(n)\n",
    "\n",
    "    # poly order 1\n",
    "    for i in range(nVars):\n",
    "        yout = np.append(yout,yin[:,i].reshape((yin.shape[0],1)),axis=1)\n",
    "\n",
    "    # poly order 2\n",
    "    if polyorder >= 2:\n",
    "        for i in range(nVars):\n",
    "            for j in range(i,nVars):\n",
    "                yout = np.append(yout,(yin[:,i]*yin[:,j]).reshape((yin.shape[0],1)),axis=1)\n",
    "\n",
    "    # poly order 3\n",
    "    if polyorder >= 3:\n",
    "        for i in range(nVars):\n",
    "            for j in range(i,nVars):\n",
    "                for k in range(j,nVars):\n",
    "                    yout = np.append(yout,(yin[:,i]*yin[:,j]*yin[:,k]).reshape((yin.shape[0],1)),axis=1)\n",
    "\n",
    "    return yout\n",
    "\n",
    "def DERIVATIVE(a, b, c):\n",
    "    dadt1 = sigma*(b - a)\n",
    "    dadt2 = rho*a - b - a*c\n",
    "    dadt3 = -beta*c + a*b\n",
    "    \n",
    "    return torch.vstack((dadt1, dadt2, dadt3))\n",
    "\n",
    "A_candidates = poolData (x_t, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"AVAILABLE PROCESSOR:\", processor, '\\n')\n",
    "\n",
    "N_modes  = 3\n",
    "x        = torch.Tensor(x).to(processor)\n",
    "y        = torch.Tensor(y).to(processor)\n",
    "z        = torch.Tensor(z).to(processor)\n",
    "t        = torch.Tensor(t).to(processor)\n",
    "\n",
    "A_candidates  = torch.Tensor (A_candidates).to(processor)\n",
    "A1A2A3_time_deriv = torch.transpose(DERIVATIVE (x, y, z), 0, 1)\n",
    "\n",
    "\n",
    "# HYPERPARAMETERS FOR THE SINDy POD METHODOLOGY\n",
    "Epochs        = 50000\n",
    "learning_rate = 1e-1\n",
    "step_epoch    = 3500\n",
    "decay_rate    = 0.50\n",
    "\n",
    "N_terms = math.comb(N_modes, 1) + math.comb(N_modes, 2) + math.comb(N_modes, 3) + N_modes\n",
    "                       \n",
    "\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 1, figsize =(20, 10))\n",
    "fig.suptitle('Ground-truth data')\n",
    "\n",
    "ax[0].plot(A1A2A3_time_deriv[:, 0].detach().cpu().numpy(), '-o') \n",
    "ax[0].set_title('$\\dot{X}$')\n",
    "\n",
    "ax[1].plot(A1A2A3_time_deriv[:, 1].detach().cpu().numpy(), '-o') \n",
    "ax[1].set_title('$\\dot{Y}$')\n",
    "\n",
    "ax[2].plot(A1A2A3_time_deriv[:, 2].detach().cpu().numpy(), '-o') \n",
    "ax[2].set_title('$\\dot{Z}$')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINE_TERM (nn.Module):\n",
    "    def __init__(self, b):\n",
    "        super().__init__()\n",
    "        self.b = b\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = torch.sin(self.b*x)\n",
    "        return output\n",
    "    \n",
    "class COSINE_TERM (nn.Module):\n",
    "    def __init__(self, b):\n",
    "        super().__init__()\n",
    "        self.b = b\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = torch.cos(self.b*x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADAPTIVE_SINDy_MODEL(nn.Module):\n",
    "    def __init__(self, a, asine, acosine):\n",
    "        super().__init__()    \n",
    "        self.a        = a\n",
    "        self.asine    = asine\n",
    "        self.acosine  = acosine\n",
    "        self.sine     = SINE_TERM   (self.asine)\n",
    "        self.cosine   = COSINE_TERM (self.acosine)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output_sine    = self.sine   (x)\n",
    "        output_cosine  = self.cosine (x)\n",
    "        output = torch.hstack((x, output_sine, output_cosine)) @ self.a\n",
    "        return output\n",
    "    \n",
    "class SINDy_MODEL(nn.Module):\n",
    "    def __init__(self, a):\n",
    "        super().__init__()    \n",
    "        self.a        = a\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        output = x @ self.a\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMPLITUDE COEFFICIENTS OF SINDy MODEL\n",
    "COEFF_ADT1 = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)\n",
    "COEFF_ADT2 = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)\n",
    "COEFF_ADT3 = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)\n",
    "COEFF_ADT4 = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)\n",
    "COEFF_ADT5 = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)\n",
    "COEFF_ADT6 = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COEFFICIENTS OF SINDy MODEL\n",
    "optim_COEFF_ADT1 = optim.Adam([COEFF_ADT1], lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_COEFF_ADT2 = optim.Adam([COEFF_ADT2], lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_COEFF_ADT3 = optim.Adam([COEFF_ADT3], lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_COEFF_ADT4 = optim.Adam([COEFF_ADT4], lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_COEFF_ADT5 = optim.Adam([COEFF_ADT5], lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_COEFF_ADT6 = optim.Adam([COEFF_ADT6], lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "# WEIGHT FUNCTION OF SINDy MODEL\n",
    "WEIGHTS3     = Parameter(torch.ones_like(COEFF_ADT3), requires_grad= True)\n",
    "WEIGHTS5     = Parameter(torch.ones_like(COEFF_ADT5), requires_grad= True)\n",
    "WEIGHTS6     = Parameter(torch.ones_like(COEFF_ADT6), requires_grad= True)\n",
    "Lambda1      = Parameter(torch.tensor(0.01),  requires_grad= True)\n",
    "Lambda2      = Parameter(torch.tensor(0.015), requires_grad= True)\n",
    "Lambda3      = Parameter(torch.tensor(0.01),  requires_grad= True)\n",
    "Lambda4      = Parameter(torch.tensor(1.0),   requires_grad= True)\n",
    "Lambda5      = Parameter(torch.tensor(1.0),   requires_grad= True)\n",
    "\n",
    "optim_weights3 = optim.Adam([WEIGHTS3], lr = learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_weights5 = optim.Adam([WEIGHTS5], lr = learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_weights6 = optim.Adam([WEIGHTS6], lr = learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "optim_Lambda4  = optim.Adam([Lambda4],  lr = learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_Lambda5  = optim.Adam([Lambda5],  lr = learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "# STEP DECAY DYNAMIC LEARNING RATE\n",
    "scheduler_ADT1   = torch.optim.lr_scheduler.StepLR(optim_COEFF_ADT1, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_ADT2   = torch.optim.lr_scheduler.StepLR(optim_COEFF_ADT2, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_ADT3   = torch.optim.lr_scheduler.StepLR(optim_COEFF_ADT3, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_ADT4   = torch.optim.lr_scheduler.StepLR(optim_COEFF_ADT4, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_ADT5   = torch.optim.lr_scheduler.StepLR(optim_COEFF_ADT5, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_ADT6   = torch.optim.lr_scheduler.StepLR(optim_COEFF_ADT6, step_size=step_epoch, gamma=decay_rate)\n",
    "\n",
    "scheduler_weights3 = torch.optim.lr_scheduler.StepLR(optim_weights3, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_weights5 = torch.optim.lr_scheduler.StepLR(optim_weights5, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_weights6 = torch.optim.lr_scheduler.StepLR(optim_weights6, step_size=step_epoch, gamma=decay_rate)\n",
    "\n",
    "scheduler_LAMBDA4  = torch.optim.lr_scheduler.StepLR(optim_Lambda4, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_LAMBDA5  = torch.optim.lr_scheduler.StepLR(optim_Lambda5, step_size=step_epoch, gamma=decay_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### CASE 1: SINDy with fixed $\\lambda$ parameter = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODE 1\n",
    "A1_DT1 = SINDy_MODEL(COEFF_ADT1 [:, 0]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 2\n",
    "A2_DT1 = SINDy_MODEL(COEFF_ADT1 [:, 1]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 3\n",
    "A3_DT1 = SINDy_MODEL(COEFF_ADT1 [:, 2]).to(processor)\n",
    "\n",
    "Loss_data1    = torch.empty(size=(Epochs, 1))\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    A1_out, A2_out, A3_out  = A1_DT1 (A_candidates), A2_DT1 (A_candidates), A3_DT1 (A_candidates)\n",
    "    output_data  = torch.stack((A1_out , A2_out, A3_out), dim = 1)\n",
    "    loss_epoch   = loss_function (A1A2A3_time_deriv, output_data) + Lambda1*torch.linalg.matrix_norm(COEFF_ADT1, ord =1)\n",
    "    \n",
    "    optim_COEFF_ADT1.zero_grad()\n",
    "    loss_epoch.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        optim_COEFF_ADT1.step()\n",
    "        Loss_data1 [epoch] = loss_epoch.detach()\n",
    "        COEFF_ADT1 [torch.abs(COEFF_ADT1) <= 0.005] = 0.0\n",
    "        \n",
    "    print('LOSS DATA, [EPOCH =', epoch,  ']:',  Loss_data1 [epoch].item())\n",
    "    print('LEARNING RATE:', optim_COEFF_ADT1.param_groups[0]['lr'])\n",
    "    print (\"*\"*85)\n",
    "       \n",
    "    scheduler_ADT1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0005\n",
    "#****************************************************************************#\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('$\\lambda_{fixed} = 0.01$')\n",
    "\n",
    "ax[0].plot(COEFF_ADT1 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT1 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[2].plot(COEFF_ADT1 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Z')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[2].xaxis.set_major_locator(loc)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(COEFF_ADT1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### CASE 2: SINDy with fixed $\\lambda$ parameter = 0.015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODE 1\n",
    "A1_DT2 = SINDy_MODEL(COEFF_ADT2 [:, 0]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 2\n",
    "A2_DT2 = SINDy_MODEL(COEFF_ADT2 [:, 1]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 3\n",
    "A3_DT2 = SINDy_MODEL(COEFF_ADT2 [:, 2]).to(processor)\n",
    "\n",
    "Loss_data2    = torch.empty(size=(Epochs, 1))\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    A1_out, A2_out, A3_out  = A1_DT2 (A_candidates), A2_DT2 (A_candidates), A3_DT2 (A_candidates)\n",
    "    output_data  = torch.stack((A1_out , A2_out, A3_out), dim = 1)\n",
    "    loss_epoch   = loss_function (A1A2A3_time_deriv, output_data) + Lambda2*torch.linalg.matrix_norm(COEFF_ADT2, ord =1)\n",
    "    \n",
    "    optim_COEFF_ADT2.zero_grad()\n",
    "    loss_epoch.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        optim_COEFF_ADT2.step()\n",
    "        Loss_data2 [epoch] = loss_epoch.detach()\n",
    "        COEFF_ADT2 [torch.abs(COEFF_ADT2) < 0.005] = 0.0\n",
    "        \n",
    "    print('LOSS DATA, [EPOCH =', epoch,  ']:',  Loss_data2 [epoch].item())\n",
    "    print('LEARNING RATE:', optim_COEFF_ADT2.param_groups[0]['lr'])\n",
    "    print (\"*\"*85)\n",
    "       \n",
    "    scheduler_ADT2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Loss_data2.detach().cpu().numpy())\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('$\\lambda_{fixed} = 0.015$')\n",
    "\n",
    "ax[0].plot(COEFF_ADT2 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT2 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[2].plot(COEFF_ADT2 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Z')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[2].xaxis.set_major_locator(loc)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(COEFF_ADT2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### CASE 3: SINDy with fixed $\\lambda$ parameter = 0.01 and adaptive weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODE 1\n",
    "A1_DT3 = SINDy_MODEL(COEFF_ADT3 [:, 0]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 2\n",
    "A2_DT3 = SINDy_MODEL(COEFF_ADT3 [:, 1]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 3\n",
    "A3_DT3 = SINDy_MODEL(COEFF_ADT3 [:, 2]).to(processor)\n",
    "\n",
    "Loss_data3    = torch.empty(size=(Epochs, 1))\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    A1_out, A2_out, A3_out  = A1_DT3 (A_candidates), A2_DT3 (A_candidates), A3_DT3 (A_candidates)\n",
    "    output_data  = torch.stack((A1_out , A2_out, A3_out), dim = 1)\n",
    "    loss_epoch   = loss_function (A1A2A3_time_deriv, output_data) + Lambda3*torch.linalg.matrix_norm(torch.abs(WEIGHTS3)*COEFF_ADT3, ord =1)\n",
    "    \n",
    "    optim_COEFF_ADT3.zero_grad()\n",
    "    optim_weights3.zero_grad()\n",
    "    loss_epoch.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        optim_COEFF_ADT3.step()\n",
    "        optim_weights3.step()\n",
    "        Loss_data3 [epoch] = loss_epoch.detach()\n",
    "        COEFF_ADT3 [torch.abs(COEFF_ADT3) < 0.005] = 0.0\n",
    "        \n",
    "    print('LOSS DATA, [EPOCH =', epoch,  ']:',  Loss_data3 [epoch].item())\n",
    "    print('LEARNING RATE:', optim_COEFF_ADT3.param_groups[0]['lr'])\n",
    "    print (\"*\"*85)\n",
    "       \n",
    "    scheduler_ADT3.step()\n",
    "    scheduler_weights3.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Loss_data3.detach().cpu().numpy())\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('$\\lambda_{fixed} = 0.01$ with Adaptive weights')\n",
    "\n",
    "ax[0].plot(COEFF_ADT3 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT3 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[2].plot(COEFF_ADT3 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Z')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[2].xaxis.set_major_locator(loc)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(COEFF_ADT3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### CASE 4: SINDy with adaptive $\\lambda$ parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODE 1\n",
    "A1_DT4 = SINDy_MODEL(COEFF_ADT4 [:, 0]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 2\n",
    "A2_DT4 = SINDy_MODEL(COEFF_ADT4 [:, 1]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 3\n",
    "A3_DT4 = SINDy_MODEL(COEFF_ADT4 [:, 2]).to(processor)\n",
    "\n",
    "Loss_data4    = torch.empty(size=(Epochs, 1))\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    A1_out, A2_out, A3_out  = A1_DT4 (A_candidates), A2_DT4 (A_candidates), A3_DT4 (A_candidates)\n",
    "    output_data  = torch.stack((A1_out , A2_out, A3_out), dim = 1)\n",
    "    loss_epoch   = loss_function (A1A2A3_time_deriv, output_data) + torch.abs(Lambda4 + 1e-12)*torch.linalg.matrix_norm(COEFF_ADT4, ord =1)\n",
    "    \n",
    "    optim_COEFF_ADT4.zero_grad()\n",
    "    optim_Lambda4.zero_grad()\n",
    "    loss_epoch.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        optim_COEFF_ADT4.step()\n",
    "        optim_Lambda4.step()\n",
    "        Loss_data4 [epoch] = loss_epoch.detach()\n",
    "        COEFF_ADT4 [torch.abs(COEFF_ADT4) < 0.005] = 0.0\n",
    "        \n",
    "    print('LOSS DATA, [EPOCH =', epoch,  ']:',  Loss_data4 [epoch].item())\n",
    "    print('LEARNING RATE:', optim_COEFF_ADT4.param_groups[0]['lr'])\n",
    "    print (\"*\"*85)\n",
    "       \n",
    "    scheduler_ADT4.step()\n",
    "    scheduler_LAMBDA4.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Loss_data4.detach().cpu().numpy())\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('Adaptive $\\lambda $')\n",
    "\n",
    "ax[0].plot(COEFF_ADT4 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT4 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[2].plot(COEFF_ADT4 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Z')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[2].xaxis.set_major_locator(loc)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(COEFF_ADT4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### CASE 5: SINDy with adaptive $\\lambda$ parameter and adaptive weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODE 1\n",
    "A1_DT5 = SINDy_MODEL(COEFF_ADT5 [:, 0]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 21\n",
    "A2_DT5 = SINDy_MODEL(COEFF_ADT5 [:, 1]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 3\n",
    "A3_DT5 = SINDy_MODEL(COEFF_ADT5 [:, 2]).to(processor)\n",
    "\n",
    "Loss_data5    = torch.empty(size=(Epochs, 1))\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    A1_out, A2_out, A3_out  = A1_DT5 (A_candidates), A2_DT5 (A_candidates), A3_DT5 (A_candidates)\n",
    "    output_data  = torch.stack((A1_out , A2_out, A3_out), dim = 1)\n",
    "    loss_epoch   = loss_function (A1A2A3_time_deriv, output_data) + torch.abs(Lambda5 + 1e-12)*torch.linalg.matrix_norm(torch.abs(WEIGHTS5)*COEFF_ADT5, ord =1)\n",
    "    \n",
    "    optim_COEFF_ADT5.zero_grad()\n",
    "    optim_Lambda5.zero_grad()\n",
    "    optim_weights5.zero_grad()\n",
    "    loss_epoch.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        optim_COEFF_ADT5.step()\n",
    "        optim_Lambda5.step()\n",
    "        optim_weights5.step()\n",
    "        Loss_data5 [epoch] = loss_epoch.detach()\n",
    "        COEFF_ADT5 [torch.abs(COEFF_ADT5) < 0.005] = 0.0\n",
    "            \n",
    "    print('LOSS DATA, [EPOCH =', epoch,  ']:',  Loss_data5 [epoch].item())\n",
    "    print('LEARNING RATE:', optim_COEFF_ADT5.param_groups[0]['lr'])\n",
    "    print (\"*\"*85)\n",
    "       \n",
    "    scheduler_ADT5.step()\n",
    "    scheduler_LAMBDA5.step()\n",
    "    scheduler_weights5.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Loss_data5.detach().cpu().numpy())\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('Adaptive $\\lambda $ + Adaptive Weights')\n",
    "\n",
    "ax[0].plot(COEFF_ADT5 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT5 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[2].plot(COEFF_ADT5 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Z')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[2].xaxis.set_major_locator(loc)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(COEFF_ADT5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### CASE 6: SINDy with adaptive weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODE 1\n",
    "A1_DT6 = SINDy_MODEL(COEFF_ADT6 [:, 0]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 2\n",
    "A2_DT6 = SINDy_MODEL(COEFF_ADT6 [:, 1]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 3\n",
    "A3_DT6 = SINDy_MODEL(COEFF_ADT6 [:, 2]).to(processor)\n",
    "\n",
    "Loss_data6    = torch.empty(size=(Epochs, 1))\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    A1_out, A2_out, A3_out  = A1_DT6 (A_candidates), A2_DT6 (A_candidates), A3_DT6 (A_candidates)\n",
    "    output_data  = torch.stack((A1_out , A2_out, A3_out), dim = 1)\n",
    "    loss_epoch   = loss_function (A1A2A3_time_deriv, output_data) + torch.linalg.matrix_norm(torch.abs(WEIGHTS6)*COEFF_ADT6, ord =1)\n",
    "    \n",
    "    optim_COEFF_ADT6.zero_grad()\n",
    "    optim_weights6.zero_grad()\n",
    "    loss_epoch.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        optim_COEFF_ADT6.step()\n",
    "        optim_weights6.step()\n",
    "        Loss_data6 [epoch] = loss_epoch.detach()\n",
    "        COEFF_ADT6 [torch.abs(COEFF_ADT6) < 0.005] = 0.0\n",
    "            \n",
    "    print('LOSS DATA, [EPOCH =', epoch,  ']:',  Loss_data6 [epoch].item())\n",
    "    print('LEARNING RATE:', optim_COEFF_ADT6.param_groups[0]['lr'])\n",
    "    print (\"*\"*85)\n",
    "       \n",
    "    scheduler_ADT6.step()\n",
    "    scheduler_weights6.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Loss_data6.detach().cpu().numpy())\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('Adaptive Weights')\n",
    "\n",
    "ax[0].plot(COEFF_ADT6 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT6 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[2].plot(COEFF_ADT6 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Z')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[2].xaxis.set_major_locator(loc)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(COEFF_ADT6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0005\n",
    "#****************************************************************************#\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('$\\lambda_{fixed} = 0.001$')\n",
    "\n",
    "ax[0].plot(COEFF_ADT1 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT1 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[2].plot(COEFF_ADT1 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Z')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[2].xaxis.set_major_locator(loc)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#****************************************************************************#\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('$\\lambda_{fixed} = 0.0001$')\n",
    "\n",
    "ax[0].plot(COEFF_ADT2 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT2 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[2].plot(COEFF_ADT2 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Z')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[2].xaxis.set_major_locator(loc)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#****************************************************************************#\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('$\\lambda_{fixed} = 0.001$ + Adaptive Weights')\n",
    "\n",
    "ax[0].plot(COEFF_ADT3 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT3 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[2].plot(COEFF_ADT3 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Z')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[2].xaxis.set_major_locator(loc)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#****************************************************************************#\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('Adaptive $\\lambda $')\n",
    "\n",
    "ax[0].plot(COEFF_ADT4 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT4 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[2].plot(COEFF_ADT4 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Z')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[2].xaxis.set_major_locator(loc)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#****************************************************************************#\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('Adaptive $\\lambda $ + Adaptive Weights')\n",
    "\n",
    "ax[0].plot(COEFF_ADT5 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT5 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[2].plot(COEFF_ADT5 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Z')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[2].xaxis.set_major_locator(loc)\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "The optimised coefficient matrix is further reduced by assuming the terms to be zero within the chosen threshold (0.001). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRUNCATED SINDy COEFFICIENTS\n",
    "C1 = torch.clone(COEFF_ADT1[:, 0]).detach()\n",
    "C1 [torch.logical_and(C1 >= -threshold, C1 <=threshold)] = 0.0\n",
    "\n",
    "C2 = torch.clone(COEFF_ADT1[:, 1]).detach()\n",
    "C2 [torch.logical_and(C2 >= -threshold, C2 <=threshold)] = 0.0\n",
    "\n",
    "C3 = torch.clone(COEFF_ADT1[:, 2]).detach()\n",
    "C3 [torch.logical_and(C3 >= -threshold, C3 <=threshold)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1_DT_Predict = A1_DT2 (A_candidates)\n",
    "A2_DT_Predict = A2_DT2 (A_candidates)\n",
    "A3_DT_Predict = A3_DT2 (A_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(15, 4))\n",
    "fig.suptitle('Comparison')\n",
    "\n",
    "ax[0].plot(A1A2A3_time_deriv[0, :].detach().cpu().numpy(), '-o', label = \"POD Mode\") \n",
    "ax[0].plot(A1_DT_Predict.detach().cpu().numpy(), label = \"SINDy\") \n",
    "ax[0].set_title('Mode 1')\n",
    "\n",
    "\n",
    "ax[1].plot(A1A2A3_time_deriv[1, :].detach().cpu().numpy(), '-o', label = \"POD Mode\") \n",
    "ax[1].plot(A2_DT_Predict.detach().cpu().numpy(), label = \"SINDy - $\\lambda_{matrix}$\") \n",
    "ax[1].set_title('Mode 2')\n",
    "\n",
    "\n",
    "ax[2].plot(A1A2A3_time_deriv[2, :].detach().cpu().numpy(), '-o', label = \"POD Mode\") \n",
    "ax[2].plot(A3_DT_Predict.detach().cpu().numpy(), label = \"Adaptive SINDy + $\\lambda_{matrix}$\")\n",
    "ax[2].legend()\n",
    "ax[2].set_title('Mode 3')\n",
    "\n",
    "fig.subplots_adjust(top=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
