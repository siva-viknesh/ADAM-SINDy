{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "##### Author  : SIVA VIKNESH \n",
    "##### Email   : siva.viknesh@sci.utah.edu / sivaviknesh14@gmail.com \n",
    "##### Address : SCI INSTITUTE, UNIVERSITY OF UTAH, SALT LAKE CITY, UTAH, USA \n",
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.ticker as plticker\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import integrate\n",
    "\n",
    "rcParams.update({'font.size': 18})\n",
    "plt.rcParams['figure.figsize'] = [12, 12]\n",
    "import vtk\n",
    "from vtk.util import numpy_support as VN\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Periodically-damped oscillator:  <br>\n",
    "Paper: Harmonic Oscillators with Nonlinear Damping\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dot{x} & = y \\\\\n",
    "\\dot{y} & = -x +a y \\hspace{1.5mm}\\text{cos}(bx)  \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Parameters: \\\\(a\\\\), \\\\(b\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "T = 200\n",
    "t = np.arange(0,T+dt,dt)\n",
    "a = -1.0\n",
    "b =  0.1\n",
    "c =  0.750\n",
    "\n",
    "\n",
    "def oscillator_deriv(x_y, t0, a = a, b = b, c = c):\n",
    "    x, y = x_y\n",
    "    return [y, a*x +(b*y)*(np.cos(c*x))]\n",
    "\n",
    "np.random.seed(123)\n",
    "x0 = (-2, 0)\n",
    "x_t = integrate.odeint(oscillator_deriv, x0, t, rtol=10**(-12),atol=10**(-12)*np.ones_like(x0))\n",
    "x, y = x_t.T\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 2, ncols = 1, figsize =(20, 10))\n",
    "fig.suptitle('Ground-truth data')\n",
    "\n",
    "ax[0].plot(t, x, '-o') \n",
    "ax[0].set(xlabel=\"t\",ylabel=\"x\")\n",
    "\n",
    "ax[1].plot(t, y, '-o') \n",
    "ax[1].set(xlabel=\"t\",ylabel=\"y\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTING THE COMBINATIONS AMONG THE THREE CHOSEN TEMPORAL MODES\n",
    "\n",
    "def POOL_DATA(yin, nVars, polyorder):\n",
    "    n = yin.shape[0]\n",
    "    yout = torch.zeros((n, 1)).to(processor)\n",
    "\n",
    "    # poly order 0\n",
    "    yout[:, 0] = torch.ones(n)\n",
    "\n",
    "    # poly order 1\n",
    "    for i in range(nVars):\n",
    "        yout = torch.cat((yout, yin[:, i].reshape((yin.shape[0], 1))), dim=1).to(processor)\n",
    "\n",
    "    # poly order 2\n",
    "    if polyorder >= 2:\n",
    "        for i in range(nVars):\n",
    "            for j in range(i, nVars):\n",
    "                yout = torch.cat((yout, (yin[:, i] * yin[:, j]).reshape((yin.shape[0], 1))), dim=1).to(processor)\n",
    "\n",
    "    # poly order 3\n",
    "    if polyorder >= 3:\n",
    "        for i in range(nVars):\n",
    "            for j in range(i, nVars):\n",
    "                for k in range(j, nVars):\n",
    "                    yout = torch.cat((yout, (yin[:, i] * yin[:, j] * yin[:, k]).reshape((yin.shape[0], 1))), dim=1).to(processor)\n",
    "\n",
    "    return yout\n",
    "\n",
    "def DERIVATIVE(x, y, a, b, c):\n",
    "    dxdt = y\n",
    "    dydt = a*x + b*y*torch.cos(c*x)    \n",
    "    return torch.vstack((dxdt, dydt)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"AVAILABLE PROCESSOR:\", processor, '\\n')\n",
    "\n",
    "N_modes  = 2\n",
    "x_t      = torch.Tensor(x_t).to(processor)\n",
    "x        = torch.Tensor(x).to(processor)\n",
    "y        = torch.Tensor(y).to(processor)\n",
    "t        = torch.Tensor(t).to(processor)\n",
    "\n",
    "A_candidates    = POOL_DATA (x_t, 2, 2).to(processor)\n",
    "A1A2_time_deriv = DERIVATIVE (x, y, a, b, c).to(processor)\n",
    "\n",
    "# HYPERPARAMETERS FOR THE SINDy POD METHODOLOGY\n",
    "Epochs        = 40000\n",
    "learning_rate = 1e-2\n",
    "step_epoch    = 2500\n",
    "decay_rate    = 0.50\n",
    "                       \n",
    "\n",
    "fig, ax = plt.subplots(nrows = 2, ncols = 1, figsize =(20, 10))\n",
    "fig.suptitle('Ground-truth data derivative')\n",
    "\n",
    "ax[0].plot(t.detach().cpu().numpy(), A1A2_time_deriv[:, 0].detach().cpu().numpy(), '-o') \n",
    "ax[0].set_title('$\\dot{X}$')\n",
    "\n",
    "ax[1].plot(t.detach().cpu().numpy(), A1A2_time_deriv[:, 1].detach().cpu().numpy(), '-o') \n",
    "ax[1].set_title('$\\dot{Y}$')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINE_TERM (nn.Module):\n",
    "    def __init__(self, b):\n",
    "        super().__init__()\n",
    "        self.b = b\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = torch.sin(self.b*x)\n",
    "        return output\n",
    "    \n",
    "class COSINE_TERM (nn.Module):\n",
    "    def __init__(self, b):\n",
    "        super().__init__()\n",
    "        self.b = b\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = torch.cos(self.b*x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADAPTIVE_SINDy_MODEL(nn.Module):\n",
    "    def __init__(self, a, asine, acosine, axsine, axcosine):\n",
    "        super().__init__()    \n",
    "        self.a        = a\n",
    "        self.asine    = asine\n",
    "        self.acosine  = acosine\n",
    "        self.axsine   = axsine\n",
    "        self.axcosine = axcosine\n",
    "        \n",
    "        self.sine     = SINE_TERM   (self.asine)\n",
    "        self.cosine   = COSINE_TERM (self.acosine)\n",
    "        self.xsine    = SINE_TERM   (self.axsine)\n",
    "        self.xcosine  = COSINE_TERM (self.axcosine)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output_sine    = self.sine   (x)\n",
    "        output_cosine  = self.cosine (x)\n",
    "\n",
    "        output_xsine   = self.xsine   (x)\n",
    "        output_xcosine = self.xcosine (x)\n",
    " \n",
    "        output_xsine   = (output_xsine  [:,None] * x[...,None]).reshape(x.shape[0], -1)\n",
    "        output_xcosine = (output_xcosine[:,None] * x[...,None]).reshape(x.shape[0], -1)\n",
    "        \n",
    "        output = torch.hstack((x, output_sine, output_cosine, output_xsine, output_xcosine)) @ self.a\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMPLITUDE COEFFICIENTS OF SINDy MODEL\n",
    "COEFF_ADT   = torch.ones(90, N_modes, requires_grad= True, device= processor)\n",
    "\n",
    "SINE_ADT    = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)\n",
    "COSINE_ADT  = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)\n",
    "XSINE_ADT   = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)\n",
    "XCOSINE_ADT = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COEFFICIENTS OF SINDy MODEL\n",
    "optim_COEFF_ADT = optim.Adam([COEFF_ADT, SINE_ADT, COSINE_ADT, XSINE_ADT, XCOSINE_ADT], lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "# WEIGHT FUNCTION OF SINDy MODEL\n",
    "WEIGHTS  = Parameter(torch.ones_like(COEFF_ADT), requires_grad= True)\n",
    "Lambda   = Parameter(torch.tensor(1.0), requires_grad= True)\n",
    "\n",
    "optim_weights = optim.Adam([WEIGHTS], lr = learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_Lambda  = optim.Adam([Lambda],  lr = learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "\n",
    "# STEP DECAY DYNAMIC LEARNING RATE\n",
    "scheduler_ADT     = torch.optim.lr_scheduler.StepLR(optim_COEFF_ADT, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_weights = torch.optim.lr_scheduler.StepLR(optim_weights,   step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_LAMBDA  = torch.optim.lr_scheduler.StepLR(optim_Lambda,    step_size=step_epoch, gamma=decay_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "**Adaptive SINDy training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODE 1\n",
    "A1_DT = ADAPTIVE_SINDy_MODEL(COEFF_ADT [:, 0], SINE_ADT [:, 0], COSINE_ADT[:, 0], XSINE_ADT [:, 0], XCOSINE_ADT[:, 0]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 2\n",
    "A2_DT = ADAPTIVE_SINDy_MODEL(COEFF_ADT [:, 1], SINE_ADT [:, 1], COSINE_ADT[:, 1], XSINE_ADT [:, 1], XCOSINE_ADT[:, 1]).to(processor)\n",
    "\n",
    "Loss_data     = torch.empty(size=(Epochs, 1))\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    A1_out, A2_out  = A1_DT (A_candidates), A2_DT (A_candidates)\n",
    "    output_data  = torch.stack((A1_out , A2_out), dim = 1)\n",
    "    loss_epoch   = loss_function (A1A2_time_deriv, output_data) + torch.linalg.matrix_norm(torch.abs(WEIGHTS)*COEFF_ADT, ord =1)\n",
    "    \n",
    "    optim_COEFF_ADT.zero_grad()\n",
    "    optim_Lambda.zero_grad()\n",
    "    optim_weights.zero_grad()\n",
    "    loss_epoch.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        optim_COEFF_ADT.step()\n",
    "        optim_Lambda.step()\n",
    "        optim_weights.step()\n",
    "        Loss_data [epoch] = loss_epoch.detach()\n",
    "        COEFF_ADT [torch.abs(COEFF_ADT) <= 0.0075] = 0.0\n",
    "        \n",
    "    print('LOSS DATA, [EPOCH =', epoch,  ']:',  Loss_data [epoch].item())\n",
    "    print('LEARNING RATE:', optim_COEFF_ADT.param_groups[0]['lr'])\n",
    "    print (\"*\"*85)\n",
    "       \n",
    "    scheduler_ADT.step()\n",
    "    scheduler_LAMBDA.step()\n",
    "    scheduler_weights.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0005\n",
    "#****************************************************************************#\n",
    "loc = plticker.MultipleLocator(base=3) # this locator puts ticks at regular intervals\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize =(14, 4))\n",
    "fig.suptitle('Adaptive SINDy')\n",
    "\n",
    "ax[0].plot(COEFF_ADT [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('X')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[0].xaxis.set_major_locator(loc)\n",
    "\n",
    "ax[1].plot(COEFF_ADT [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Y')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "ax[1].xaxis.set_major_locator(loc)\n",
    "\n",
    "fig.subplots_adjust(top=0.8)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(COEFF_ADT[torch.nonzero(COEFF_ADT[:, 0]), 0])\n",
    "print(COEFF_ADT[torch.nonzero(COEFF_ADT[:, 1]), 1])\n",
    "print(XCOSINE_ADT[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
