{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f36f991",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "### Author  : SIVA VIKNESH \n",
    "### Email   : siva.viknesh@sci.utah.edu / sivaviknesh14@gmail.com \n",
    "### Address : SCI INSTITUTE, UNIVERSITY OF UTAH, SALT LAKE CITY, UTAH, USA \n",
    "<hr style=\"border:2px solid gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fefaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import vtk\n",
    "from vtk.util import numpy_support as VN\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743b1cb",
   "metadata": {},
   "source": [
    "Here, we consider a unsteady flow inside a symmetric stenosed coronary artery computed by imposing time-varying inlet flow rate using an open sourced - SimVascular FEM fluid solver. The post-stenoic velocity flow field over a grid of 512X512 is used for the project work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 512\n",
    "y_dim = 512\n",
    "data_file = \"data_\"\n",
    "directory = os.getcwd()  # GET THE CURRENT WORKING DIRECTORY  \n",
    "path      = directory + '/'\n",
    "data_file = path + data_file\n",
    "Nfiles    = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc43bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fieldname  = 'Vmag'\n",
    "Vel_data   = np.zeros((x_dim*y_dim, Nfiles))\n",
    "\n",
    "for i in range(Nfiles):\n",
    "    file_name = data_file + str(i) + \".vtk\"\n",
    "    print ('READING THE DATA FILE: ', file_name[len(directory)+1:])\n",
    "    reader = vtk.vtkStructuredGridReader()\n",
    "    reader.SetFileName(file_name)\n",
    "    reader.Update()\n",
    "    data = reader.GetOutput()\n",
    "    pointData = data.GetPointData().GetArray(fieldname)\n",
    "    velocity  = np.reshape(VN.vtk_to_numpy(pointData), (1, x_dim*y_dim))\n",
    "    Vel_data [:, i] = (2.0*velocity - np.min(velocity) - np.max(velocity))/ (np.max(velocity) - np.min(velocity))\n",
    "    print (\"*\"*85)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf31c3",
   "metadata": {},
   "source": [
    "First, we normalize the temporal velocity data by its spatially averaged mean value at a given time instant. Then, the matrix size is transformed to a square matrix, thereby computing the SVD operation more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, E, V  = np.linalg.svd(Vel_data, full_matrices=False)\n",
    "Eigen_val = np.sqrt(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(12, 3))\n",
    "fig.suptitle('Singular Values Spectrum')\n",
    "\n",
    "ax[0].plot(Eigen_val, '-o')\n",
    "ax[0].set(xlabel=\"Modes\",ylabel=\"Singular Values\")\n",
    "\n",
    "ax[1].plot(Eigen_val, 'o')\n",
    "ax[1].set(xlabel=\"Modes\",ylabel=\"Singular Values\")\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "ax[2].plot(np.cumsum(Eigen_val)/np.sum(Eigen_val), '-o')\n",
    "ax[2].set(xlabel=\"Modes\",ylabel=\"Cumulative Energy\")\n",
    "fig.subplots_adjust(wspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode1 = np.reshape(U[:, 0], (x_dim, y_dim))\n",
    "mode2 = np.reshape(U[:, 1], (x_dim, y_dim))\n",
    "mode3 = np.reshape(U[:, 2], (x_dim, y_dim))\n",
    "\n",
    "coeff1 = V [0, :]\n",
    "coeff2 = V [1, :]\n",
    "coeff3 = V [2, :]\n",
    "coeff4 = V [3, :]\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(12, 3))\n",
    "fig.suptitle('Spatial Modes')\n",
    "\n",
    "ax[0].contourf(mode1) \n",
    "ax[0].set_title('Mode 1')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].contourf(mode2) \n",
    "ax[1].set_title('Mode 2')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].contourf(mode3) \n",
    "ax[2].set_title('Mode 3')\n",
    "ax[2].axis('off')\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 4, figsize =(12, 3))\n",
    "fig.suptitle('Temporal Modes')\n",
    "\n",
    "ax[0].plot(coeff1) \n",
    "ax[0].set_title('Mode 1')\n",
    "\n",
    "ax[1].plot(coeff2)\n",
    "ax[1].set_title('Mode 2')\n",
    "\n",
    "\n",
    "ax[2].plot(coeff3)\n",
    "ax[2].set_title('Mode 3')\n",
    "\n",
    "ax[3].plot(coeff4)\n",
    "ax[3].set_title('Mode 4')\n",
    "\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(14, 4))\n",
    "fig.suptitle('Mode Pair Trajectories')\n",
    "\n",
    "ax[0].plot(coeff1, coeff2) \n",
    "ax[0].set_title('Mode 1')\n",
    "ax[0].set_xlabel('$\\mathregular{a_1}$')\n",
    "ax[0].set_ylabel('$\\mathregular{a_2}$')\n",
    "\n",
    "ax[1].plot(coeff1, coeff3)\n",
    "ax[1].set_title('Mode 2')\n",
    "ax[1].set_xlabel('$\\mathregular{a_1}$')\n",
    "ax[1].set_ylabel('$\\mathregular{a_3}$')\n",
    "\n",
    "ax[2].plot(coeff1, coeff4)\n",
    "ax[2].set_title('Mode 3')\n",
    "ax[2].set_xlabel('$\\mathregular{a_1}$')\n",
    "ax[2].set_ylabel('$\\mathregular{a_4}$')\n",
    "fig.subplots_adjust(top=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00642a92",
   "metadata": {},
   "source": [
    "SINDy computation starts from here, utilizing the computed PCA modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"AVAILABLE PROCESSOR:\", processor, '\\n')\n",
    "\n",
    "N_modes     = 3\n",
    "modes       = torch.Tensor(V [:N_modes, :]).to(processor)\n",
    "\n",
    "# HYPERPARAMETERS FOR THE SINDy POD METHODOLOGY\n",
    "Epochs        = 15000\n",
    "learning_rate = 1e-3\n",
    "step_epoch    = 3500\n",
    "decay_rate    = 0.50\n",
    "\n",
    "N_terms = math.comb(N_modes, 1) + math.comb(N_modes, 2) + math.comb(N_modes, 3) + N_modes\n",
    "\n",
    "# COMPUTING THE COMBINATIONS AMONG THE THREE CHOSEN TEMPORAL MODES\n",
    "A1 = modes [0, :].reshape(1, -1)\n",
    "A2 = modes [1, :].reshape(1, -1)\n",
    "A3 = modes [2, :].reshape(1, -1)\n",
    "\n",
    "A1A2   = (A1*A2).reshape(1, -1) \n",
    "A2A3   = (A2*A3).reshape(1, -1)\n",
    "A3A1   = (A3*A1).reshape(1, -1)\n",
    "\n",
    "A11A2  = (A1*A1*A2).reshape(1, -1) \n",
    "A22A3  = (A2*A2*A3).reshape(1, -1)\n",
    "A33A1  = (A3*A3*A1).reshape(1, -1)\n",
    "\n",
    "A1A22  = (A1*A2*A2).reshape(1, -1) \n",
    "A2A33  = (A2*A3*A3).reshape(1, -1)\n",
    "A3A11  = (A3*A1*A1).reshape(1, -1)\n",
    "\n",
    "A1A2A3 = (A1*A2*A3).reshape(1, -1)\n",
    "\n",
    "A11A2A3 = (A1*A1*A2*A3).reshape(1, -1)\n",
    "A1A22A3 = (A1*A2*A2*A3).reshape(1, -1)\n",
    "A1A2A33 = (A1*A2*A3*A3).reshape(1, -1)\n",
    "\n",
    "A11A22A3 = (A1*A1*A2*A2*A3).reshape(1, -1)\n",
    "A1A22A33 = (A1*A2*A2*A3*A3).reshape(1, -1)\n",
    "A11A2A33 = (A1*A1*A2*A3*A3).reshape(1, -1)\n",
    "\n",
    "A_candidates = torch.transpose(torch.vstack ((torch.ones_like(A1), A1, A2, A3, A1A2, A2A3, A3A1, A11A2, A22A3, A33A1, A1A22, A2A33, A3A11, A1A2A3,\n",
    "                              A11A2A3, A1A22A3, A1A2A33, A11A22A3, A1A22A33, A11A2A33)), 0, 1)\n",
    "print(A_candidates.shape)                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DERIVATIVE(a, Nfiles):\n",
    "    dadt = torch.zeros_like(a)\n",
    "    for i in range(Nfiles-1):\n",
    "        dadt [:, i] = a[:, i+1] - a[:, i]\n",
    "    dadt [:, -1] = a[:, -2] - a[:, -1]\n",
    "    return dadt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINDy_MODEL(nn.Module):\n",
    "    def __init__(self, a):\n",
    "        super().__init__()    \n",
    "        self.a  = a\n",
    "    def forward(self, x):\n",
    "        output = x @ self.a\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMPLITUDE COEFFICIENTS OF SINDy MODEL\n",
    "\n",
    "# NO Lambda\n",
    "COEFF_ADT1 = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)\n",
    "\n",
    "# Static Scalar Lambda\n",
    "COEFF_ADT2 = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)\n",
    "\n",
    "# Dynamic Scalar Lambda\n",
    "COEFF_ADT3 = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)\n",
    "\n",
    "# Dynamic matrix Lambda\n",
    "COEFF_ADT4 = torch.ones(A_candidates.shape[1], N_modes, requires_grad= True, device= processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2f33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COEFFICIENTS OF SINDy MODEL\n",
    "optim_COEFF_ADT1 = optim.Adam([COEFF_ADT1],  lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_COEFF_ADT2 = optim.Adam([COEFF_ADT2],  lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_COEFF_ADT3 = optim.Adam([COEFF_ADT3],  lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_COEFF_ADT4 = optim.Adam([COEFF_ADT4],  lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "# WEIGHT FUNCTION OF SINDy MODEL\n",
    "W_FUNCTION2   = Parameter(torch.tensor(0.001), requires_grad= True)\n",
    "W_FUNCTION3   = Parameter(torch.tensor(0.001), requires_grad= True)\n",
    "W_FUNCTION4   = Parameter(torch.ones_like(COEFF_ADT4), requires_grad= True)\n",
    "\n",
    "optim_Lambda3  = optim.Adam([W_FUNCTION3], lr = learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "optim_Lambda4  = optim.Adam([W_FUNCTION4], lr = learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "# STEP DECAY DYNAMIC LEARNING RATE\n",
    "scheduler_COEFF_ADT1 = torch.optim.lr_scheduler.StepLR(optim_COEFF_ADT1, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_COEFF_ADT2 = torch.optim.lr_scheduler.StepLR(optim_COEFF_ADT2, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_COEFF_ADT3 = torch.optim.lr_scheduler.StepLR(optim_COEFF_ADT3, step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_COEFF_ADT4 = torch.optim.lr_scheduler.StepLR(optim_COEFF_ADT4, step_size=step_epoch, gamma=decay_rate)\n",
    "\n",
    "scheduler_LAMBDA3    = torch.optim.lr_scheduler.StepLR(optim_Lambda3,    step_size=step_epoch, gamma=decay_rate)\n",
    "scheduler_LAMBDA4    = torch.optim.lr_scheduler.StepLR(optim_Lambda4,    step_size=step_epoch, gamma=decay_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d6dd0",
   "metadata": {},
   "source": [
    "**CASE I: SINDy with $\\lambda = 0$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc871d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1A2A3_time_deriv = DERIVATIVE (modes, Nfiles)\n",
    "\n",
    "# TEMPORAL MODE 1\n",
    "A1_DT = SINDy_MODEL(COEFF_ADT1[:, 0]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 2\n",
    "A2_DT = SINDy_MODEL(COEFF_ADT1[:, 1]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 3\n",
    "A3_DT = SINDy_MODEL(COEFF_ADT1[:, 2]).to(processor)\n",
    "\n",
    "Loss_data1     = torch.empty(size=(Epochs, 1))\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    A1_out, A2_out, A3_out  = A1_DT (A_candidates), A2_DT (A_candidates), A3_DT (A_candidates)\n",
    "    output_data  = torch.vstack((A1_out , A2_out, A3_out))\n",
    "    loss_epoch   = loss_function (A1A2A3_time_deriv, output_data)\n",
    "    \n",
    "    optim_COEFF_ADT1.zero_grad()\n",
    "    loss_epoch.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        optim_COEFF_ADT1.step()       \n",
    "        Loss_data1 [epoch] = loss_epoch.detach()\n",
    "        \n",
    "    print('LOSS DATA, [EPOCH =', epoch,  ']:',  Loss_data1 [epoch].item())\n",
    "    print('LEARNING RATE:', optim_COEFF_ADT1.param_groups[0]['lr'])\n",
    "    print (\"*\"*85)\n",
    "       \n",
    "    scheduler_COEFF_ADT1.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b67bf4",
   "metadata": {},
   "source": [
    "**CASE 2: SINDy with $\\lambda = 0.1$. In this case, $\\lambda$ is chosen to be fixed during training process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODE 1\n",
    "A1_DT = SINDy_MODEL(COEFF_ADT2 [:, 0]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 2\n",
    "A2_DT = SINDy_MODEL(COEFF_ADT2 [:, 1]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 3\n",
    "A3_DT = SINDy_MODEL(COEFF_ADT2 [:, 2]).to(processor)\n",
    "\n",
    "Loss_data2    = torch.empty(size=(Epochs, 1))\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    A1_out, A2_out, A3_out  = A1_DT (A_candidates), A2_DT (A_candidates), A3_DT (A_candidates)\n",
    "    output_data  = torch.vstack((A1_out , A2_out, A3_out))\n",
    "    loss_epoch   = loss_function (A1A2A3_time_deriv, output_data) + torch.linalg.matrix_norm(W_FUNCTION2*COEFF_ADT2, ord =1)\n",
    "    \n",
    "    optim_COEFF_ADT2.zero_grad()    \n",
    "    loss_epoch.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        optim_COEFF_ADT2.step()      \n",
    "        Loss_data2 [epoch] = loss_epoch.detach()\n",
    "        \n",
    "    print('LOSS DATA, [EPOCH =', epoch,  ']:',  Loss_data2 [epoch].item())\n",
    "    print('LEARNING RATE:', optim_COEFF_ADT1.param_groups[0]['lr'])\n",
    "    print (\"*\"*85)\n",
    "       \n",
    "    scheduler_COEFF_ADT2.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f95dcd0",
   "metadata": {},
   "source": [
    "**CASE 3: SINDy with  dynamic scalar $\\lambda$. In this case,  the scalar $\\lambda$ is optimised  during training process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODE 1\n",
    "A1_DT = SINDy_MODEL(COEFF_ADT3 [:, 0]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 2\n",
    "A2_DT = SINDy_MODEL(COEFF_ADT3 [:, 1]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 3\n",
    "A3_DT = SINDy_MODEL(COEFF_ADT3 [:, 2]).to(processor)\n",
    "\n",
    "Loss_data3    = torch.empty(size=(Epochs, 1))\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    A1_out, A2_out, A3_out  = A1_DT (A_candidates), A2_DT (A_candidates), A3_DT (A_candidates)\n",
    "    output_data  = torch.vstack((A1_out , A2_out, A3_out))\n",
    "    loss_epoch   = loss_function (A1A2A3_time_deriv, output_data) + torch.linalg.matrix_norm(torch.abs(W_FUNCTION3)*COEFF_ADT3, ord =1)\n",
    "    \n",
    "    optim_COEFF_ADT3.zero_grad()\n",
    "    optim_Lambda3.zero_grad()\n",
    "    loss_epoch.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        optim_COEFF_ADT3.step()    \n",
    "        optim_Lambda3.step()\n",
    "        Loss_data3 [epoch] = loss_epoch.detach()\n",
    "        \n",
    "    print('LOSS DATA, [EPOCH =', epoch,  ']:',  Loss_data3 [epoch].item())\n",
    "    print('LEARNING RATE:', optim_COEFF_ADT3.param_groups[0]['lr'])\n",
    "    print (\"*\"*85)\n",
    "       \n",
    "    scheduler_COEFF_ADT3.step()\n",
    "    scheduler_LAMBDA3.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9f2ab6",
   "metadata": {},
   "source": [
    "**CASE 4: SINDy with  dynamic matrix $\\lambda $. In this case,  the matrix $\\lambda$ is optimised  during training process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORAL MODE 1\n",
    "A1_DT = SINDy_MODEL(COEFF_ADT4 [:, 0]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 2\n",
    "A2_DT = SINDy_MODEL(COEFF_ADT4 [:, 1]).to(processor)\n",
    "\n",
    "# TEMPORAL MODE 3\n",
    "A3_DT = SINDy_MODEL(COEFF_ADT4 [:, 2]).to(processor)\n",
    "\n",
    "Loss_data4     = torch.empty(size=(Epochs, 1))\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    A1_out, A2_out, A3_out  = A1_DT (A_candidates), A2_DT (A_candidates), A3_DT (A_candidates)\n",
    "    output_data  = torch.vstack((A1_out , A2_out, A3_out))\n",
    "    loss_epoch   = loss_function (A1A2A3_time_deriv, output_data) + torch.linalg.matrix_norm(torch.abs(W_FUNCTION4)*COEFF_ADT4, ord =1)\n",
    "    \n",
    "    optim_COEFF_ADT4.zero_grad()\n",
    "    optim_Lambda4.zero_grad()\n",
    "    \n",
    "    loss_epoch.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        optim_COEFF_ADT4.step()\n",
    "        optim_Lambda4.step()        \n",
    "        Loss_data4 [epoch] = loss_epoch.detach()\n",
    "        \n",
    "    print('LOSS DATA, [EPOCH =', epoch,  ']:',  Loss_data4 [epoch].item())\n",
    "    print('LEARNING RATE:', optim_COEFF_ADT4.param_groups[0]['lr'])\n",
    "    print (\"*\"*85)\n",
    "       \n",
    "    scheduler_COEFF_ADT4.step()\n",
    "    scheduler_LAMBDA4.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881df67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Loss_data1.detach().cpu().numpy(), label = \"$\\lambda = 0$\")\n",
    "plt.plot(Loss_data2.detach().cpu().numpy(), label = \"$\\lambda = 10^{-2}$\")\n",
    "plt.plot(Loss_data3.detach().cpu().numpy(), label = \"$\\lambda_{scalar}$\")\n",
    "plt.plot(Loss_data4.detach().cpu().numpy(), label = \"$\\lambda_{matrix}$\")\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b588ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.001\n",
    "#****************************************************************************#\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(12, 3))\n",
    "fig.suptitle('$\\lambda = 0$')\n",
    "\n",
    "ax[0].plot(COEFF_ADT1 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('Mode 1')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "\n",
    "ax[1].plot(COEFF_ADT1 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Mode 2')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "\n",
    "ax[2].plot(COEFF_ADT1 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Mode 3')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "fig.subplots_adjust(top=0.8)\n",
    "plt.show()\n",
    "\n",
    "#****************************************************************************#\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(12, 3))\n",
    "fig.suptitle('$\\lambda = 10^{-2} $')\n",
    "\n",
    "ax[0].plot(COEFF_ADT2 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('Mode 1')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "\n",
    "ax[1].plot(COEFF_ADT2 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Mode 2')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "\n",
    "ax[2].plot(COEFF_ADT2 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Mode 3')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "fig.subplots_adjust(top=0.8)\n",
    "plt.show()\n",
    "\n",
    "#****************************************************************************#\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(12, 3))\n",
    "fig.suptitle('$\\lambda_{scalar} $')\n",
    "\n",
    "ax[0].plot(COEFF_ADT3 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('Mode 1')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "\n",
    "ax[1].plot(COEFF_ADT3 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Mode 2')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "\n",
    "ax[2].plot(COEFF_ADT3 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Mode 3')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "fig.subplots_adjust(top=0.8)\n",
    "plt.show()\n",
    "#****************************************************************************#\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(12, 3))\n",
    "fig.suptitle('$\\lambda_{matrix} $')\n",
    "\n",
    "ax[0].plot(COEFF_ADT4 [:, 0].detach().cpu().numpy(), 'o') \n",
    "ax[0].set_title('Mode 1')\n",
    "ax[0].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[0].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "\n",
    "ax[1].plot(COEFF_ADT4 [:, 1].detach().cpu().numpy(), 'o') \n",
    "ax[1].set_title('Mode 2')\n",
    "ax[1].axhline(y =  threshold, color = 'r', linestyle = '-')\n",
    "ax[1].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "\n",
    "ax[2].plot(COEFF_ADT4 [:, 2].detach().cpu().numpy(), 'o') \n",
    "ax[2].set_title('Mode 3')\n",
    "ax[2].axhline(y = threshold, color = 'r', linestyle = '-')\n",
    "ax[2].axhline(y = -threshold, color = 'r', linestyle = '-')\n",
    "fig.subplots_adjust(top=0.8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8326a",
   "metadata": {},
   "source": [
    "The optimised coefficient matrix is further reduced by assuming the terms to be zero within the chosen threshold (0.001). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af710f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRUNCATED SINDy COEFFICIENTS\n",
    "\n",
    "# CASE 2: LAMBDA\n",
    "C1_h1 = torch.clone(COEFF_ADT2[:, 0]).detach()\n",
    "C1_h1[torch.logical_and(C1_h1>=-threshold, C1_h1<=threshold)] = 0.0\n",
    "\n",
    "C2_h1 = torch.clone(COEFF_ADT2[:, 1]).detach()\n",
    "C2_h1[torch.logical_and(C2_h1>=-threshold, C2_h1<=threshold)] = 0.0\n",
    "\n",
    "C3_h1 = torch.clone(COEFF_ADT2[:, 2]).detach()\n",
    "C3_h1[torch.logical_and(C3_h1>=-threshold, C3_h1<=threshold)] = 0.0\n",
    "\n",
    "#****************************************************************************#\n",
    "\n",
    "# CASE 4: LAMBDA\n",
    "C1_h2 = torch.clone(COEFF_ADT4[:, 0]).detach()\n",
    "C1_h2[torch.logical_and(C1_h2>=-threshold, C1_h2<=threshold)] = 0.0\n",
    "\n",
    "C2_h2 = torch.clone(COEFF_ADT4[:, 1]).detach()\n",
    "C2_h2[torch.logical_and(C2_h2>=-threshold, C2_h2<=threshold)] = 0.0\n",
    "\n",
    "C3_h2 = torch.clone(COEFF_ADT4[:, 2]).detach()\n",
    "C3_h2[torch.logical_and(C3_h2>=-threshold, C3_h2<=threshold)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558415f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1_DT_Predict1 = A_candidates @ C1_h1\n",
    "A2_DT_Predict1 = A_candidates @ C2_h1\n",
    "A3_DT_Predict1 = A_candidates @ C3_h1\n",
    "\n",
    "A1_DT_Predict2 = A_candidates @ C1_h2\n",
    "A2_DT_Predict2 = A_candidates @ C2_h2\n",
    "A3_DT_Predict2 = A_candidates @ C3_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 3, figsize =(15, 4))\n",
    "fig.suptitle('TEMPORAL POD MODES')\n",
    "\n",
    "ax[0].plot(A1A2A3_time_deriv[0, :].detach().cpu().numpy(), 'o', label = \"POD Mode\") \n",
    "ax[0].plot(A1_DT_Predict1.detach().cpu().numpy(), label = \"SINDy : $\\lambda = 10^{-2}$\") \n",
    "ax[0].plot(A1_DT_Predict2.detach().cpu().numpy(), label = \"SINDy - $\\lambda_{matrix}$\") \n",
    "ax[0].set_title('Mode 1')\n",
    "\n",
    "\n",
    "ax[1].plot(A1A2A3_time_deriv[1, :].detach().cpu().numpy(), 'o', label = \"POD Mode\") \n",
    "ax[1].plot(A2_DT_Predict1.detach().cpu().numpy(), label = \"SINDy - $\\lambda = 10^{-2}$\") \n",
    "ax[1].plot(A2_DT_Predict2.detach().cpu().numpy(), label = \"SINDy - $\\lambda_{matrix}$\") \n",
    "ax[1].set_title('Mode 2')\n",
    "\n",
    "\n",
    "ax[2].plot(A1A2A3_time_deriv[2, :].detach().cpu().numpy(), 'o', label = \"POD Mode\") \n",
    "ax[2].plot(A3_DT_Predict1.detach().cpu().numpy(), label = \"SINDy : $\\lambda = 10^{-2}$\") \n",
    "ax[2].plot(A3_DT_Predict2.detach().cpu().numpy(), label = \"SINDy : $\\lambda_{matrix}$\")\n",
    "ax[2].legend()\n",
    "ax[2].set_title('Mode 3')\n",
    "\n",
    "fig.subplots_adjust(top=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72312c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
